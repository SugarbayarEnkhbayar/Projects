knitr::opts_chunk$set(echo = TRUE)
df=read.csv("df.csv")
head(df)
for (i in 2:32) {
x=colnames(df)[i]
df[,i]<-paste0(x,'-',df[,i])
}
head(df)
df=read.csv("df.csv")
head(df)
df=read.csv("df.csv",row.names = F)
head(df)
df=read.csv("df.csv",row.names = F)
?read.csv
df=read.csv("df.csv")
head(df)
library(readr)
library(readr)
library(tidyverse)
library(readr)
library(tidyverse)
library(arules)
library(arulesViz)
df=df %>% select(-X)
head(df)
for (i in 2:32) {
x=colnames(df)[i]
df[,i]<-paste0(x,'-',df[,i])
}
for (i in 1:31) {
x=colnames(df)[i]
df[,i]<-paste0(x,'-',df[,i])
}
head(df)
df=read.csv("df.csv")
df=df %>% select(-X)
head(df)
for (i in 1:31) {
x=colnames(df)[i]
df[,i]<-paste0(x,'-',df[,i])
}
head(df)
head(df)
df<-df %>% select(-age,-absences)
head(df)
sapply(df,class)
sapply(df,function(x)sum(is.na(x)))
library(PerformanceAnalytics)
View(df)
df=read.csv("df.csv")
View(df)
unique(df$age)
unique(df$Medu)
unique(df$Fedu)
unique(df$traveltime)
unique(df$studytime)
unique(df$failures)
unique(df$famrel)
unique(df$freetime)
unique(df$goout)
unique(df$Dalc)
unique(df$Walc)
unique(df$health)
unique(df$absences)
---
title: "Market basket analysis"
author: "Sugarbayar Enkhbayar"
date: "2/10/2023"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Introduction
I used market basket analysis and student performance data from 2 schools in Portugal to find out what factors influence whether students pass or not final exam. In other words, I selected student pass or not data as rhs. And I selected other student profile information as lhs.
## Packages
```{r eval=T,warning=F,message=F}
library(readr)
library(tidyverse)
library(arules)
library(arulesViz)
```
## Datasets
### Data preparetion
```{r eval=T,warning=F,message=F}
df=read.csv("df.csv")
df=df %>% select(-X)
head(df)
for (i in 1:31) {
x=colnames(df)[i]
df[,i]<-paste0(x,'-',df[,i])
}
head(df)
```
## Exploratory Data Analysis {.tabsett}
### Variable identification
```{r eval=T,warning=F,message=F}
df<-df %>% select(-age,-absences)
write.csv(df,"df1.csv",row.names = F)
colnames(df)
sapply(df,class)
```
### Missing values treatment
```{r eval=T,warning=F,message=F}
sapply(df,function(x)sum(is.na(x)))
```
### Univariate analysis
#### Central Tendency
```{r eval=T,warning=F,message=F}
summary(df)
```
#### Measure of dispersion
```{r eval=T,warning=F,message=F}
library(e1071)
library(moments)
tibble(
Column   = names(df),
Variance = purrr::map_dbl(df, var),
SD       = purrr::map_dbl(df, sd),
IQR      = purrr::map_dbl(df,IQR),
SKW      = purrr::map_dbl(df,skewness),
KRT      = purrr::map_dbl(df,kurtosis))
```
View(df)
df=read.csv("df.csv")
df=df %>% select(-X)
df<-df %>% select(-age,-absences)
write.csv(df,"df1.csv",row.names = F)
colnames(df)
sapply(df,class)
sapply(df,function(x)sum(is.na(x)))
summary(df)
data=df
---
title: "Market basket analysis"
author: "Sugarbayar Enkhbayar"
date: "2/10/2023"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Introduction
I used market basket analysis and student performance data from 2 schools in Portugal to find out what factors influence whether students pass or not final exam. In other words, I selected student pass or not data as rhs. And I selected other student profile information as lhs.
## Packages
```{r eval=T,warning=F,message=F}
library(readr)
library(tidyverse)
library(arules)
library(arulesViz)
```
## Datasets
### Data preparetion
```{r eval=T,warning=F,message=F}
df=read.csv("df.csv")
df=df %>% select(-X)
head(df)
data=df
for (i in 1:31) {
x=colnames(df)[i]
df[,i]<-paste0(x,'-',df[,i])
}
head(df)
```
## Exploratory Data Analysis {.tabsett}
### Variable identification
```{r eval=T,warning=F,message=F}
df<-df %>% select(-age,-absences)
write.csv(df,"df1.csv",row.names = F)
colnames(df)
sapply(df,class)
```
### Missing values treatment
```{r eval=T,warning=F,message=F}
sapply(df,function(x)sum(is.na(x)))
```
### Univariate analysis
#### Central Tendency
```{r eval=T,warning=F,message=F}
summary(df)
```
#### Measure of dispersion
```{r eval=T,warning=F,message=F}
library(e1071)
library(moments)
tibble(
Column   = names(df),
Variance = purrr::map_dbl(df, var),
SD       = purrr::map_dbl(df, sd),
IQR      = purrr::map_dbl(df,IQR),
SKW      = purrr::map_dbl(df,skewness),
KRT      = purrr::map_dbl(df,kurtosis))
```
#### Visualization of EDA
```{r eval=T,warning=F,message=F}
boxplot()
hist()
```
### Bi-variate analysis
```{r eval=T,warning=F,message=F}
library(PerformanceAnalytics)
chart.Correlation(df)
```
## Non-hierarchical method {.tabset}
View(data)
boxplot(data$school)
boxplot(data)
boxplot(data$Medu)
boxplot(data$Medu,data$Fedu)
boxplot(data$traveltime,data$studytime)
boxplot(data$traveltime,data$studytime,data$failures)
boxplot(data$famrel)
boxplot(data$freetime)
boxplot(data$freetime,data$goout,data$Dalc)
boxplot(data$freetime,data$goout,data$Dalc,data$Walc,data$health)
boxplot(data$Medu,data$Fedu)
boxplot(data$traveltime,data$studytime,data$failures)
boxplot(data$famrel)
boxplot(data$freetime,data$goout,data$Dalc,data$Walc,data$health)
hist()
boxplot(data$Medu,data$Fedu)
hist(data$Medu,data$Fedu)
hist(data$Medu)
hist(data$Fedu,add=T)
hist(data$Medu)
hist(data$Fedu,add=T)
set.seed(1)
Ixos=rnorm(4000 , 120 , 30)
Primadur=rnorm(4000 , 200 , 30)
# First distribution
hist(Ixos, breaks=30, xlim=c(0,300), col=rgb(1,0,0,0.5), xlab="height",
ylab="nbr of plants", main="distribution of height of 2 durum wheat varieties" )
# Second with add=T to plot on top
hist(Primadur, breaks=30, xlim=c(0,300), col=rgb(0,0,1,0.5), add=T)
hist(data$Medu)
hist(data$Medu)
hist(data$Fedu)
boxplot(data$Medu,data$Fedu)
boxplot(data$traveltime,data$studytime,data$failures)
boxplot(data$famrel)
boxplot(data$freetime,data$goout,data$Dalc,data$Walc,data$health)
library(PerformanceAnalytics)
library(PerformanceAnalytics)
chart.Correlation(data)
summarize(df$Medu)
summarize(df$Medu)
summarize(df$Medu)
summary(df$Medu)
tb=data %>% select(Medu,Fedu,traveltime,studytime,failures,famrel,freetime,goout,Dalc,Walc,health)
tibble(
Column   = names(tb),
Variance = purrr::map_dbl(tb, var),
SD       = purrr::map_dbl(tb, sd),
IQR      = purrr::map_dbl(tb,IQR),
SKW      = purrr::map_dbl(tb,skewness),
KRT      = purrr::map_dbl(tb,kurtosis))
# what is the profile of students who are passed final exam 'final-success'?
rules<-apriori(data=trans1, parameter=list(supp=0.1,conf = 0.5),
appearance=list(default="lhs", rhs='final-success'), control=list(verbose=F))
---
title: "Market basket analysis"
author: "Sugarbayar Enkhbayar"
date: "2/10/2023"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Introduction
I used market basket analysis and student performance data from 2 schools in Portugal to find out what factors influence whether students pass or not final exam. In other words, I selected student pass or not data as rhs. And I selected other student profile information as lhs.
## Packages
```{r eval=T,warning=F,message=F}
library(readr)
library(tidyverse)
library(arules)
library(arulesViz)
```
## Data preparetion
```{r eval=T,warning=F,message=F}
df=read.csv("df.csv")
df=df %>% select(-X)
head(df)
data=df
for (i in 1:31) {
x=colnames(df)[i]
df[,i]<-paste0(x,'-',df[,i])
}
head(df)
```
## Exploratory Data Analysis {.tabsett}
### Variable identification
```{r eval=T,warning=F,message=F}
df<-df %>% select(-age,-absences)
write.csv(df,"df1.csv",row.names = F)
colnames(df)
sapply(df,class)
```
### Missing values treatment
```{r eval=T,warning=F,message=F}
sapply(df,function(x)sum(is.na(x)))
```
### Central Tendency
```{r eval=T,warning=F,message=F}
summary(df)
library(e1071)
library(moments)
tb=data %>% select(Medu,Fedu,traveltime,studytime,failures,famrel,freetime,goout,Dalc,Walc,health)
tibble(
Column   = names(tb),
Variance = purrr::map_dbl(tb, var),
SD       = purrr::map_dbl(tb, sd),
IQR      = purrr::map_dbl(tb,IQR),
SKW      = purrr::map_dbl(tb,skewness),
KRT      = purrr::map_dbl(tb,kurtosis))
```
### Visualization of EDA
```{r eval=T,warning=F,message=F}
boxplot(data$Medu,data$Fedu)
boxplot(data$traveltime,data$studytime,data$failures)
boxplot(data$famrel)
boxplot(data$freetime,data$goout,data$Dalc,data$Walc,data$health)
```
## Manually categorised {.tabset}
```{r eval=T,warning=F,message=F}
trans=read.transactions("df1.csv",format='basket',sep=",",skip=0)
summary(trans)
length(trans)
trans
inspect(head(trans))
size(trans)
length(trans)
# cleaning the data from rare observations
trans1=trans[,itemFrequency(trans)>0.05]
trans1
# we can get all levels in dataset and their frequency
sort(itemFrequency(trans1, type="relative"))
itemFrequencyPlot(trans1,type='relative',topN=15)
```
# what is the profile of students who are passed final exam 'final-success'?
rules<-apriori(data=trans1, parameter=list(supp=0.1,conf = 0.5),
appearance=list(default="lhs", rhs='final-success'), control=list(verbose=F))
trans1
library(readr)
library(tidyverse)
library(arules)
library(arulesViz)
df=read.csv("df.csv")
df=df %>% select(-X)
head(df)
data=df
for (i in 1:31) {
x=colnames(df)[i]
df[,i]<-paste0(x,'-',df[,i])
}
head(df)
df<-df %>% select(-age,-absences)
write.csv(df,"df1.csv",row.names = F)
colnames(df)
sapply(df,class)
sapply(df,function(x)sum(is.na(x)))
summary(df)
library(e1071)
library(moments)
tb=data %>% select(Medu,Fedu,traveltime,studytime,failures,famrel,freetime,goout,Dalc,Walc,health)
tibble(
Column   = names(tb),
Variance = purrr::map_dbl(tb, var),
SD       = purrr::map_dbl(tb, sd),
IQR      = purrr::map_dbl(tb,IQR),
SKW      = purrr::map_dbl(tb,skewness),
KRT      = purrr::map_dbl(tb,kurtosis))
boxplot(data$Medu,data$Fedu)
boxplot(data$traveltime,data$studytime,data$failures)
boxplot(data$famrel)
boxplot(data$freetime,data$goout,data$Dalc,data$Walc,data$health)
trans=read.transactions("df1.csv",format='basket',sep=",",skip=0)
summary(trans)
length(trans)
trans
inspect(head(trans))
inspect(head(trans))
size(trans)
length(trans)
# cleaning the data from rare observations
trans1=trans[,itemFrequency(trans)>0.05]
trans1
# we can get all levels in dataset and their frequency
sort(itemFrequency(trans1, type="relative"))
itemFrequencyPlot(trans1,type='relative',topN=15)
# what is the profile of students who are passed final exam 'final-success'?
rules<-apriori(data=trans1, parameter=list(supp=0.1,conf = 0.5),
appearance=list(default="lhs", rhs='final-success'), control=list(verbose=F))
summary(rules) # see how many rules and what are the parameters of support and confidence
#rules.clean<-rules[!is.redundant(rules)]
#rules.clean<-rules.clean[is.significant(rules.clean, trans1)]
#rules.clean<-rules.clean[is.maximal(rules.clean)]
rules.clean<-rules
rules.final<-sort(rules.clean, by="support", decreasing=TRUE)
summary(rules.final)
rules.final<-sort(rules.final, by="support", decreasing=TRUE)
inspect(head(rules.final,10))
#Support defines the frequency of features combination in dataset – it is obvious that shorter phrases appear more often than longer ones.
#Coverage (also cover, LHS-support) is the support of the left-hand-side of the rule. Confidence – when 1 (100%) it means that for sure (100%) if we see somebody very happy in Sommerville,
#he/she estimates schools as good, takes own decisions, thinks that police always help, is similar to others, can easily have affordable house and sees the city as beautiful
#(remember that this relation does not have to be opposite). When lift > 1 we see features appearing together more often than separately (lift defines how many times more often).
plot(head(rules.final,10), method="graph", engine="htmlwidget") #
aff.items<-dissimilarity(trans1, which="items", method="affinity")
hc<-hclust(aff.items, method="ward.D2")
plot(hc, main="Dendrogram for Items")
aff.rules<-dissimilarity(rules.final, method="affinity", args=list(transactions=trans1))
plot(hc, main="Dendrogram for Rules (Affinity)")
# what is the profile of students who are passed final exam 'final-success'?
rules<-apriori(data=trans1, parameter=list(supp=0.1,conf = 0.5),
appearance=list(default="lhs", rhs='final-success'), control=list(verbose=F))
summary(rules) # see how many rules and what are the parameters of support and confidence
#rules.clean<-rules[!is.redundant(rules)]
#rules.clean<-rules.clean[is.significant(rules.clean, trans1)]
#rules.clean<-rules.clean[is.maximal(rules.clean)]
rules.clean<-rules
rules.final<-sort(rules.clean, by="support", decreasing=TRUE)
summary(rules.final)
rules.final<-sort(rules.final, by="support", decreasing=TRUE)
inspect(head(rules.final,10))
#Support defines the frequency of features combination in dataset – it is obvious that shorter phrases appear more often than longer ones.
#Coverage (also cover, LHS-support) is the support of the left-hand-side of the rule. Confidence – when 1 (100%) it means that for sure (100%) if we see somebody very happy in Sommerville,
#he/she estimates schools as good, takes own decisions, thinks that police always help, is similar to others, can easily have affordable house and sees the city as beautiful
#(remember that this relation does not have to be opposite). When lift > 1 we see features appearing together more often than separately (lift defines how many times more often).
plot(head(rules.final,10), method="graph", engine="htmlwidget") #
aff.items<-dissimilarity(trans1, which="items", method="affinity")
hc<-hclust(aff.items, method="ward.D2")
plot(hc, main="Dendrogram for Items")
aff.rules<-dissimilarity(rules.final, method="affinity", args=list(transactions=trans1))
summary(tb)
par(mfrow = c(2,2)) # two rows, one column
boxplot(data$Medu,data$Fedu)
boxplot(data$traveltime,data$studytime,data$failures)
boxplot(data$famrel)
boxplot(data$freetime,data$goout,data$Dalc,data$Walc,data$health)
?boxplot
boxplot(data$Medu,data$Fedu,names = c('Medu','Fedu'))
boxplot(data$traveltime,data$studytime,data$failures,names=c("traveltime",'studytime','failures'))
boxplot(data$Medu,data$Fedu,names = c('Medu','Fedu'))
boxplot(data$traveltime,data$studytime,data$failures,names=c("traveltime",'studytime','failures'))
boxplot(data$famrel,names='famrel')
boxplot(data$famrel,names=c('famrel'))
boxplot(data$famrel,names=c('famrel'))
boxplot(data$famrel,name=c('famrel'))
boxplot(data$freetime,data$goout,data$Dalc,data$Walc,data$health,mes=c("freetime",'goout','Dalc','Walc','health'))
boxplot(data$freetime,data$goout,data$Dalc,data$Walc,data$health,names=c("freetime",'goout','Dalc','Walc','health'))
?sort
# we can get all levels in dataset and their frequency
sort(itemFrequency(trans1, type="relative"),decreasing = F)
# we can get all levels in dataset and their frequency
sort(itemFrequency(trans1, type="relative"),decreasing = T)
?apriori
#rules.clean<-rules[!is.redundant(rules)]
#rules.clean<-rules.clean[is.significant(rules.clean, trans1)]
#rules.clean<-rules.clean[is.maximal(rules.clean)]
rules.clean<-rules
rules.final<-sort(rules.clean, by="lift", decreasing=TRUE)
summary(rules.final)
rules.final<-sort(rules.final, by="lift", decreasing=TRUE)
inspect(head(rules.final,10))
rules<-apriori(data=trans1, parameter=list(supp=0.1,conf = 0.5),
appearance=list(default="lhs", rhs='final-fail'), control=list(verbose=F))
summary(rules)
rules.clean<-rules
rules.final<-sort(rules.clean, by="lift", decreasing=TRUE)
summary(rules.final)
data.ass=sort(data.ass,by='support',decreasing = TRUE)
trans2=df
for (i in 1:29) {
trans2[,i]<-factor(trans2[,i],levels = unique(trans2[,i]))
}
trans21=trans2 %>% filter(final=='final-success')
data.disc=discretizeDF.supervised(data=trans21,final~.,methods = 'chi2')
summary(data.disc)
data.trans<-transactions(data.disc)
trans2<-data.trans[, itemFrequency(data.trans)>0.05]
data.ass<-mineCARs(final~ ., transactions=trans2, support=0.04, confidence=0.7)
data.ass=sort(data.ass,by='support',decreasing = TRUE)
summary(data.ass)
library(arulesCBA)
trans2=df
for (i in 1:29) {
trans2[,i]<-factor(trans2[,i],levels = unique(trans2[,i]))
}
trans21=trans2 %>% filter(final=='final-success')
data.disc=discretizeDF.supervised(data=trans21,final~.,methods = 'chi2')
summary(data.disc)
data.trans<-transactions(data.disc)
trans2<-data.trans[, itemFrequency(data.trans)>0.05]
data.ass<-mineCARs(final~ ., transactions=trans2, support=0.04, confidence=0.7)
data.ass<-mineCARs(final~ ., transactions=trans2, support=0.04, confidence=0.7)
data.ass=sort(data.ass,by='lift',decreasing = TRUE)
data.ass=sort(data.ass,by='lift',decreasing = TRUE)
summary(data.ass)
inspect(head(data.ass,20))
